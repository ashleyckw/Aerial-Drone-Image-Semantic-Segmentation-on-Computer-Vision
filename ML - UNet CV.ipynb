{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout \n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import concatenate\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path of image and mask dataset\n",
    "IMAGE_PATH = 'drone/dataset/semantic_drone_dataset/original_images/'\n",
    "MASK_PATH = 'drone/dataset/semantic_drone_dataset/label_images_semantic/'\n",
    "\n",
    "# 23 classes\n",
    "NUM_CLASSES = 23 \n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of image dataset\n",
    "def create_df():\n",
    "    name = []\n",
    "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
    "        for filename in filenames:\n",
    "            name.append(filename.split('.')[0])\n",
    "    \n",
    "    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images :  400\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "def preprocess_data(X, y, size):\n",
    "    X_processed = []\n",
    "    y_processed = []\n",
    "    for i in tqdm(range(len(X))):\n",
    "        img = cv2.imread(IMAGE_PATH + X[i] + '.jpg')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(MASK_PATH + y[i] + '.png', 0)\n",
    "        img = cv2.resize(img, size)\n",
    "        mask = cv2.resize(mask, size, interpolation=cv2.INTER_NEAREST)\n",
    "        X_processed.append(img.reshape(-1, 256, 256, 3))\n",
    "        y_processed.append(mask.reshape(-1, 256, 256, 1))\n",
    "    X_processed = np.concatenate(X_processed, axis=0)\n",
    "    y_processed = np.concatenate(y_processed, axis=0)\n",
    "    return X_processed, y_processed\n",
    "\n",
    "df = create_df()\n",
    "print('Total Images : ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train & test set\n",
    "# X_trainval, X_test = train_test_split(df['id'].values, test_size=0.3, random_state=19)\n",
    "# X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n",
    "\n",
    "# print('Train Size   : ', len(X_train))\n",
    "# print('Val Size     : ', len(X_val))\n",
    "# print('Test Size    : ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a817c32b3aa4d97b139f2d0abd72934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the desired size of the resized images\n",
    "size = (256, 256)\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed, y_processed = preprocess_data(df['id'].values, df['id'].values, size)\n",
    "# X_val_processed, y_val_processed = preprocess_data(X_val, X_val, size)\n",
    "# X_test_processed, y_test_processed = preprocess_data(X_test, X_test, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 256, 256, 3)\n",
      "(400, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_processed & y_processed\n",
    "print(X_processed.shape)\n",
    "print(y_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform semantic segmentation on one of the images in the dataset\n",
    "def predictMask(image_id):\n",
    "    # image_id = '513'\n",
    "    img = cv2.imread(IMAGE_PATH + image_id + '.jpg')\n",
    "    # img = cv2.imread(\"btest2.jpg\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(MASK_PATH + image_id + '.png', 0)\n",
    "\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    mask_resized = cv2.resize(mask, size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    img_processed = img_resized.reshape(-1, 3)\n",
    "    \n",
    "    return img_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay, roc_curve\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluateMask(true_mask, predicted_mask): \n",
    "    # Flatten the masks to 1D arrays\n",
    "    true_mask = to_categorical(true_mask.flatten(), num_classes=23)\n",
    "    predicted_mask = to_categorical(predicted_mask.flatten(), num_classes=23)\n",
    "    \n",
    "    # Mean Iou Score\n",
    "    mean_iou = MeanIoU(num_classes=23)\n",
    "    mean_iou.update_state(true_mask, predicted_mask)\n",
    "    iou_score = mean_iou.result().numpy()\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(np.argmax(true_mask, axis=1), np.argmax(predicted_mask, axis=1), labels=range(23))\n",
    "    \n",
    "    # Calculate the metrics\n",
    "    tp = np.diag(cm)\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    tn = np.sum(cm) - (tp + fp + fn)\n",
    "\n",
    "    sns.heatmap(cm, annot=True)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    precision_mean = np.mean(np.nan_to_num(precision))\n",
    "    recall = tp / (tp + fn)\n",
    "    recall_mean = np.mean(np.nan_to_num(recall))\n",
    "    accuracy = np.sum(tp) / np.sum(cm)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    f1_score_mean = np.mean(np.nan_to_num(f1_score))\n",
    "    dice_coefficient = (2 * tp) / (2 * tp + fp + fn)\n",
    "    dice_coefficient_mean = np.mean(np.nan_to_num(dice_coefficient))\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Classification Report:\\n\", classification_report(np.argmax(true_mask, axis=1), np.argmax(predicted_mask, axis=1)))\n",
    "    print(\"Mean IoU score:\", iou_score)\n",
    "    print(\"Recall:\", recall_mean)\n",
    "    print(\"Precision:\", precision_mean)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"F1 score:\", f1_score_mean)\n",
    "    print(\"Dice coefficient:\", dice_coefficient_mean)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    sns.heatmap(cm, xticklabels=['P0', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7'\n",
    "                                 , 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14'\n",
    "                                 , 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', \n",
    "                                 'P21', 'P22'], \n",
    "                yticklabels=['A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7'\n",
    "                            , 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15'\n",
    "                            , 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22'],\n",
    "    annot=True, fmt='d', annot_kws={'fontsize':6}, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,      \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(inputs)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  3,   \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)      \n",
    "    \n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(2,strides=2)(conv)\n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    result = []\n",
    "    for layer in model.layers:\n",
    "        descriptors = [layer.__class__.__name__, layer.output_shape, layer.count_params()]\n",
    "        if (type(layer) == Conv2D):\n",
    "            descriptors.append(layer.padding)\n",
    "            descriptors.append(layer.activation.__name__)\n",
    "            descriptors.append(layer.kernel_initializer.__class__.__name__)\n",
    "        if (type(layer) == MaxPooling2D):\n",
    "            descriptors.append(layer.pool_size)\n",
    "        if (type(layer) == Dropout):\n",
    "            descriptors.append(layer.rate)\n",
    "        result.append(descriptors)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1:\n",
      "['InputLayer', [(None, 256, 256, 3)], 0]\n",
      "['Conv2D', (None, 256, 256, 32), 896, 'same', 'relu', 'HeNormal']\n",
      "['Conv2D', (None, 256, 256, 32), 9248, 'same', 'relu', 'HeNormal']\n",
      "['MaxPooling2D', (None, 128, 128, 32), 0, (2, 2)]\n",
      "\n",
      "Block 2:\n",
      "['InputLayer', [(None, 256, 256, 3)], 0]\n",
      "['Conv2D', (None, 256, 256, 1024), 28672, 'same', 'relu', 'HeNormal']\n",
      "['Conv2D', (None, 256, 256, 1024), 9438208, 'same', 'relu', 'HeNormal']\n",
      "['Dropout', (None, 256, 256, 1024), 0, 0.1]\n",
      "['MaxPooling2D', (None, 128, 128, 1024), 0, (2, 2)]\n"
     ]
    }
   ],
   "source": [
    "input_size=(256, 256, 3)\n",
    "n_filters = 32\n",
    "inputs = Input(input_size)\n",
    "cblock1 = conv_block(inputs, n_filters * 1)\n",
    "model1 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
    "\n",
    "output1 = [['InputLayer', [(None, 256, 256, 3)], 0],\n",
    "            ['Conv2D', (None, 256, 256, 32), 896, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 256, 256, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "            ['MaxPooling2D', (None, 128, 128, 32), 0, (2, 2)]]\n",
    "\n",
    "print('Block 1:')\n",
    "for layer in summary(model1):\n",
    "    print(layer)\n",
    "\n",
    "#comparator(summary(model1), output1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "cblock1 = conv_block(inputs, n_filters * 32, dropout_prob=0.1, max_pooling=True)\n",
    "model2 = tf.keras.Model(inputs=inputs, outputs=cblock1)\n",
    "\n",
    "output2 = [['InputLayer', [(None, 256, 256, 3)], 0],\n",
    "            ['Conv2D', (None, 256, 256, 1024), 28672, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 256, 256, 1024), 9438208, 'same', 'relu', 'HeNormal'],\n",
    "            ['Dropout', (None, 256, 256, 1024), 0, 0.1],\n",
    "            ['MaxPooling2D', (None, 128, 128, 1024), 0, (2, 2)]]\n",
    "           \n",
    "print('\\nBlock 2:')   \n",
    "for layer in summary(model2):\n",
    "    print(layer)\n",
    "    \n",
    "#comparator(summary(model2), output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,    \n",
    "                 3,   \n",
    "                 strides=2,\n",
    "                 padding='same')(expansive_input)\n",
    "\n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    conv = Conv2D(n_filters,   \n",
    "                 3,     \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 3,   \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1:\n",
      "['InputLayer', [(None, 32, 32, 256)], 0]\n",
      "['Conv2DTranspose', (None, 64, 64, 32), 73760]\n",
      "['InputLayer', [(None, 64, 64, 128)], 0]\n",
      "['Concatenate', (None, 64, 64, 160), 0]\n",
      "['Conv2D', (None, 64, 64, 32), 46112, 'same', 'relu', 'HeNormal']\n",
      "['Conv2D', (None, 64, 64, 32), 9248, 'same', 'relu', 'HeNormal']\n"
     ]
    }
   ],
   "source": [
    "input_size1=(32, 32, 256)\n",
    "input_size2 = (64, 64, 128)\n",
    "n_filters = 32\n",
    "expansive_inputs = Input(input_size1)\n",
    "contractive_inputs =  Input(input_size2)\n",
    "cblock1 = upsampling_block(expansive_inputs, contractive_inputs, n_filters * 1)\n",
    "model1 = tf.keras.Model(inputs=[expansive_inputs, contractive_inputs], outputs=cblock1)\n",
    "\n",
    "output1 = [['InputLayer', [(None, 32, 32, 256)], 0],\n",
    "            ['Conv2DTranspose', (None, 64, 64, 32), 73760],\n",
    "            ['InputLayer', [(None, 64, 64, 128)], 0],\n",
    "            ['Concatenate', (None, 64, 64, 160), 0],\n",
    "            ['Conv2D', (None, 64, 64, 32), 46112, 'same', 'relu', 'HeNormal'],\n",
    "            ['Conv2D', (None, 64, 64, 32), 9248, 'same', 'relu', 'HeNormal']]\n",
    "\n",
    "print('Block 1:')\n",
    "for layer in summary(model1):\n",
    "    print(layer)\n",
    "\n",
    "#comparator(summary(model1), output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(256, 256, 3), n_filters=32, n_classes=23):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    cblock1 = conv_block(inputs, n_filters)\n",
    "    \n",
    "    cblock2 = conv_block(cblock1[0], n_filters*2)\n",
    "    cblock3 = conv_block(cblock2[0], n_filters*4)\n",
    "    cblock4 = conv_block(cblock3[0], n_filters*8, dropout_prob=0.3) \n",
    "    cblock5 = conv_block(cblock4[0], n_filters*16, dropout_prob=0.3, max_pooling=None) \n",
    "    \n",
    "    ublock6 = upsampling_block(cblock5[0],cblock4[1] ,  n_filters * 8)\n",
    "     \n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters*2)\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters*1)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model_output = [['InputLayer', [(None, 256, 256, 3)], 0],\n",
    "['Conv2D', (None, 256, 256, 32), 896, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 256, 256, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "['MaxPooling2D', (None, 128, 128, 32), 0, (2, 2)],\n",
    "['Conv2D', (None, 128, 128, 64), 18496, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 128, 128, 64), 36928, 'same', 'relu', 'HeNormal'],\n",
    "['MaxPooling2D', (None, 64, 64, 64), 0, (2, 2)],\n",
    "['Conv2D', (None, 64, 64, 128), 73856, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 64, 64, 128), 147584, 'same', 'relu', 'HeNormal'],\n",
    "['MaxPooling2D', (None, 32, 32, 128), 0, (2, 2)],\n",
    "['Conv2D', (None, 32, 32, 256), 295168, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 32, 32, 256), 590080, 'same', 'relu', 'HeNormal'],\n",
    "['Dropout', (None, 32, 32, 256), 0, 0.3],\n",
    "['MaxPooling2D', (None, 16, 16, 256), 0, (2, 2)],\n",
    "['Conv2D', (None, 16, 16, 512), 1180160, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 16, 16, 512), 2359808, 'same', 'relu', 'HeNormal'],\n",
    "['Dropout', (None, 16, 16, 512), 0, 0.3],\n",
    "['Conv2DTranspose', (None, 32, 32, 256), 1179904],\n",
    "['Concatenate', (None, 32, 32, 512), 0],\n",
    "['Conv2D', (None, 32, 32, 256), 1179904, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 32, 32, 256), 590080, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2DTranspose', (None, 64, 64, 128), 295040],\n",
    "['Concatenate', (None, 64, 64, 256), 0],\n",
    "['Conv2D', (None, 64, 64, 128), 295040, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 64, 64, 128), 147584, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2DTranspose', (None, 128, 128, 64), 73792],\n",
    "['Concatenate', (None, 128, 128, 128), 0],\n",
    "['Conv2D', (None, 128, 128, 64), 73792, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 128, 128, 64), 36928, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2DTranspose', (None, 256, 256, 32), 18464],\n",
    "['Concatenate', (None, 256, 256, 64), 0],\n",
    "['Conv2D', (None, 256, 256, 32), 18464, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 256, 256, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 256, 256, 32), 9248, 'same', 'relu', 'HeNormal'],\n",
    "['Conv2D', (None, 256, 256, 23), 759, 'same', 'linear', 'GlorotUniform']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return unet_model((IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 200\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def cross_validation(num_folds):\n",
    "    kf = KFold(n_splits=num_folds)\n",
    "    cv_scores, model_history = list(), list()\n",
    "\n",
    "    for train, test in kf.split(X_processed, y_processed):\n",
    "        cv_model = None\n",
    "        cv_model = create_model()\n",
    "        cv_model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss=loss,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        X_train, X_test = X_processed[train], X_processed[test]\n",
    "        y_train, y_test = y_processed[train], y_processed[test]\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "        validation_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "        train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "        validation_dataset = validation_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "        cv_model.save_weights('cv_unet.h5')\n",
    "        history = cv_model.fit(train_dataset,validation_data=validation_dataset, epochs=EPOCHS, batch_size=8, callbacks=[es])\n",
    "        _, val_acc = cv_model.evaluate(validation_dataset, verbose = 1)\n",
    "        cv_model.load_weights('cv_unet.h5')\n",
    "        print('>%.3f' % val_acc)\n",
    "        cv_scores.append(val_acc)\n",
    "        model_history.append(cv_model)\n",
    "\n",
    "    return np.mean(cv_scores), np.std(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "40/40 [==============================] - 14s 257ms/step - loss: 14.0565 - accuracy: 0.2796 - val_loss: 2.5501 - val_accuracy: 0.4091\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 9s 232ms/step - loss: 2.3998 - accuracy: 0.4307 - val_loss: 2.2056 - val_accuracy: 0.4847\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 2.1743 - accuracy: 0.4909 - val_loss: 2.0682 - val_accuracy: 0.5152\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 9s 234ms/step - loss: 2.0481 - accuracy: 0.5164 - val_loss: 1.9917 - val_accuracy: 0.5311\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 2.0006 - accuracy: 0.5138 - val_loss: 1.8920 - val_accuracy: 0.5382\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 1.8880 - accuracy: 0.5218 - val_loss: 1.7963 - val_accuracy: 0.5434\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 1.8254 - accuracy: 0.5302 - val_loss: 1.7335 - val_accuracy: 0.5470\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 1.7704 - accuracy: 0.5343 - val_loss: 1.6967 - val_accuracy: 0.5479\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.7116 - accuracy: 0.5412 - val_loss: 1.6462 - val_accuracy: 0.5493\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.6803 - accuracy: 0.5456 - val_loss: 1.6243 - val_accuracy: 0.5509\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.6691 - accuracy: 0.5479 - val_loss: 1.5969 - val_accuracy: 0.5572\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.6386 - accuracy: 0.5557 - val_loss: 1.6144 - val_accuracy: 0.5567\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.6224 - accuracy: 0.5581 - val_loss: 1.5771 - val_accuracy: 0.5594\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.5896 - accuracy: 0.5616 - val_loss: 1.5209 - val_accuracy: 0.5634\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.5493 - accuracy: 0.5713 - val_loss: 1.5339 - val_accuracy: 0.5621\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 1.5579 - accuracy: 0.5668 - val_loss: 1.5167 - val_accuracy: 0.5631\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.5195 - accuracy: 0.5711 - val_loss: 1.5055 - val_accuracy: 0.5645\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4919 - accuracy: 0.5759 - val_loss: 1.4785 - val_accuracy: 0.5702\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.4565 - accuracy: 0.5826 - val_loss: 1.4447 - val_accuracy: 0.5749\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.4458 - accuracy: 0.5868 - val_loss: 1.4381 - val_accuracy: 0.5760\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.4393 - accuracy: 0.5881 - val_loss: 1.4391 - val_accuracy: 0.5768\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 1.4268 - accuracy: 0.5898 - val_loss: 1.4499 - val_accuracy: 0.5719\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4454 - accuracy: 0.5848 - val_loss: 1.4177 - val_accuracy: 0.5767\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 1.4119 - accuracy: 0.5900 - val_loss: 1.3989 - val_accuracy: 0.5810\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.3876 - accuracy: 0.5948 - val_loss: 1.4256 - val_accuracy: 0.5744\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.6309 - accuracy: 0.5626 - val_loss: 1.6472 - val_accuracy: 0.5488\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.9358 - accuracy: 0.5447 - val_loss: 1.6314 - val_accuracy: 0.5379\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 1.6408 - accuracy: 0.5391 - val_loss: 1.5256 - val_accuracy: 0.5514\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.5559 - accuracy: 0.5527 - val_loss: 1.4955 - val_accuracy: 0.5611\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.5231 - accuracy: 0.5593 - val_loss: 1.4915 - val_accuracy: 0.5628\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4970 - accuracy: 0.5641 - val_loss: 1.4646 - val_accuracy: 0.5662\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.4732 - accuracy: 0.5679 - val_loss: 1.4531 - val_accuracy: 0.5686\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.4650 - accuracy: 0.5687 - val_loss: 1.4481 - val_accuracy: 0.5683\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.4564 - accuracy: 0.5702Restoring model weights from the end of the best epoch: 24.\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4564 - accuracy: 0.5702 - val_loss: 1.4439 - val_accuracy: 0.5709\n",
      "Epoch 34: early stopping\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 1.3989 - accuracy: 0.5810\n",
      ">0.581\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 11s 249ms/step - loss: 34.2225 - accuracy: 0.2023 - val_loss: 3.4135 - val_accuracy: 0.2150\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 2.9064 - accuracy: 0.2676 - val_loss: 2.5783 - val_accuracy: 0.3132\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 2.5095 - accuracy: 0.3925 - val_loss: 2.3331 - val_accuracy: 0.4227\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 2.3108 - accuracy: 0.4618 - val_loss: 2.2127 - val_accuracy: 0.4511\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 2.2119 - accuracy: 0.4793 - val_loss: 2.1311 - val_accuracy: 0.4703\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 2.1218 - accuracy: 0.4844 - val_loss: 2.0641 - val_accuracy: 0.4649\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 2.0432 - accuracy: 0.4993 - val_loss: 2.0066 - val_accuracy: 0.5045\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 1.9746 - accuracy: 0.5292 - val_loss: 1.9644 - val_accuracy: 0.5048\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.9136 - accuracy: 0.5378 - val_loss: 1.9055 - val_accuracy: 0.5210\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 1.8602 - accuracy: 0.5500 - val_loss: 1.8599 - val_accuracy: 0.5257\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.8284 - accuracy: 0.5556 - val_loss: 1.8369 - val_accuracy: 0.5248\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.7851 - accuracy: 0.5574 - val_loss: 1.7936 - val_accuracy: 0.5283\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.7485 - accuracy: 0.5635 - val_loss: 1.7645 - val_accuracy: 0.5360\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.7093 - accuracy: 0.5699 - val_loss: 1.7221 - val_accuracy: 0.5409\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 15s 370ms/step - loss: 1.6809 - accuracy: 0.5715 - val_loss: 1.7236 - val_accuracy: 0.5426\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.6421 - accuracy: 0.5810 - val_loss: 1.6382 - val_accuracy: 0.5652\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.6255 - accuracy: 0.5797 - val_loss: 1.6522 - val_accuracy: 0.5564\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 1.6029 - accuracy: 0.5858 - val_loss: 1.6286 - val_accuracy: 0.5608\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.5811 - accuracy: 0.5884 - val_loss: 1.5852 - val_accuracy: 0.5781\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 1.5814 - accuracy: 0.5863 - val_loss: 1.6348 - val_accuracy: 0.5666\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.5297 - accuracy: 0.6020 - val_loss: 1.5078 - val_accuracy: 0.5973\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.4973 - accuracy: 0.6085 - val_loss: 1.5096 - val_accuracy: 0.6001\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4987 - accuracy: 0.6043 - val_loss: 1.5364 - val_accuracy: 0.5791\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4340 - accuracy: 0.6169 - val_loss: 1.4104 - val_accuracy: 0.6233\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.3990 - accuracy: 0.6213 - val_loss: 1.4242 - val_accuracy: 0.6016\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.3879 - accuracy: 0.6237 - val_loss: 1.4378 - val_accuracy: 0.6149\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.3763 - accuracy: 0.6256 - val_loss: 1.3969 - val_accuracy: 0.6136\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.3249 - accuracy: 0.6384 - val_loss: 1.3499 - val_accuracy: 0.6372\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.3311 - accuracy: 0.6288 - val_loss: 1.3216 - val_accuracy: 0.6344\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.2748 - accuracy: 0.6438 - val_loss: 1.3297 - val_accuracy: 0.6315\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.2562 - accuracy: 0.6506 - val_loss: 1.2775 - val_accuracy: 0.6370\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2378 - accuracy: 0.6491 - val_loss: 1.2733 - val_accuracy: 0.6299\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 1.2245 - accuracy: 0.6501 - val_loss: 1.3299 - val_accuracy: 0.6065\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 1.2355 - accuracy: 0.6473 - val_loss: 1.3074 - val_accuracy: 0.6239\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.1837 - accuracy: 0.6612 - val_loss: 1.2193 - val_accuracy: 0.6401\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 1.1717 - accuracy: 0.6626 - val_loss: 1.1961 - val_accuracy: 0.6531\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.1171 - accuracy: 0.6737 - val_loss: 1.1727 - val_accuracy: 0.6566\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.0872 - accuracy: 0.6828 - val_loss: 1.1646 - val_accuracy: 0.6677\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 1.0712 - accuracy: 0.6864 - val_loss: 1.1412 - val_accuracy: 0.6724\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.1297 - accuracy: 0.6695 - val_loss: 1.2930 - val_accuracy: 0.6188\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.0852 - accuracy: 0.6862 - val_loss: 1.1732 - val_accuracy: 0.6626\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.0544 - accuracy: 0.6929 - val_loss: 1.1514 - val_accuracy: 0.6765\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 1.0160 - accuracy: 0.7023 - val_loss: 1.1021 - val_accuracy: 0.6825\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.0448 - accuracy: 0.6917 - val_loss: 1.1379 - val_accuracy: 0.6708\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 1.0079 - accuracy: 0.7054 - val_loss: 1.1362 - val_accuracy: 0.6783\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.0669 - accuracy: 0.6880 - val_loss: 1.3248 - val_accuracy: 0.5939\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.0173 - accuracy: 0.7010 - val_loss: 1.1236 - val_accuracy: 0.6781\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.9927 - accuracy: 0.7095 - val_loss: 1.1503 - val_accuracy: 0.6816\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 15s 371ms/step - loss: 0.9850 - accuracy: 0.7155 - val_loss: 1.1326 - val_accuracy: 0.6721\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 0.9594 - accuracy: 0.7218 - val_loss: 1.1047 - val_accuracy: 0.6868\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 10s 247ms/step - loss: 0.9665 - accuracy: 0.7191 - val_loss: 1.3544 - val_accuracy: 0.6053\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 10s 246ms/step - loss: 1.0072 - accuracy: 0.7056 - val_loss: 1.6370 - val_accuracy: 0.5473\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.0850 - accuracy: 0.6847Restoring model weights from the end of the best epoch: 43.\n",
      "40/40 [==============================] - 10s 245ms/step - loss: 1.0850 - accuracy: 0.6847 - val_loss: 1.1686 - val_accuracy: 0.6645\n",
      "Epoch 53: early stopping\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 1.1021 - accuracy: 0.6825\n",
      ">0.682\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 11s 246ms/step - loss: 6.9910 - accuracy: 0.2358 - val_loss: 2.5140 - val_accuracy: 0.3836\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 2.2357 - accuracy: 0.4528 - val_loss: 2.2127 - val_accuracy: 0.4790\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 2.0185 - accuracy: 0.5016 - val_loss: 1.9702 - val_accuracy: 0.5195\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 15s 382ms/step - loss: 1.9049 - accuracy: 0.5204 - val_loss: 1.9378 - val_accuracy: 0.5182\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 1.8249 - accuracy: 0.5347 - val_loss: 1.8485 - val_accuracy: 0.5347\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 1.7311 - accuracy: 0.5479 - val_loss: 1.7268 - val_accuracy: 0.5494\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 16s 413ms/step - loss: 1.6763 - accuracy: 0.5536 - val_loss: 1.7038 - val_accuracy: 0.5471\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 1.6250 - accuracy: 0.5595 - val_loss: 1.6107 - val_accuracy: 0.5609\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 16s 411ms/step - loss: 1.5834 - accuracy: 0.5655 - val_loss: 1.6640 - val_accuracy: 0.5497\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 14s 340ms/step - loss: 1.5538 - accuracy: 0.5740 - val_loss: 1.5486 - val_accuracy: 0.5712\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4990 - accuracy: 0.5829 - val_loss: 1.5183 - val_accuracy: 0.5762\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4707 - accuracy: 0.5882 - val_loss: 1.5840 - val_accuracy: 0.5625\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.4626 - accuracy: 0.5902 - val_loss: 1.5402 - val_accuracy: 0.5722\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.4128 - accuracy: 0.5968 - val_loss: 1.4140 - val_accuracy: 0.5954\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.3805 - accuracy: 0.6028 - val_loss: 1.3925 - val_accuracy: 0.6068\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.3530 - accuracy: 0.6121 - val_loss: 1.3570 - val_accuracy: 0.6093\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.3209 - accuracy: 0.6190 - val_loss: 1.3268 - val_accuracy: 0.6248\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.2602 - accuracy: 0.6357 - val_loss: 1.2614 - val_accuracy: 0.6383\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2263 - accuracy: 0.6437 - val_loss: 1.2211 - val_accuracy: 0.6484\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.1898 - accuracy: 0.6539 - val_loss: 1.2027 - val_accuracy: 0.6561\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.1497 - accuracy: 0.6676 - val_loss: 1.2333 - val_accuracy: 0.6609\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1292 - accuracy: 0.6736 - val_loss: 1.1490 - val_accuracy: 0.6648\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.0934 - accuracy: 0.6803 - val_loss: 1.1100 - val_accuracy: 0.6749\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.0708 - accuracy: 0.6843 - val_loss: 1.1135 - val_accuracy: 0.6738\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.0568 - accuracy: 0.6902 - val_loss: 1.1301 - val_accuracy: 0.6729\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.0293 - accuracy: 0.6970 - val_loss: 1.1336 - val_accuracy: 0.6690\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.0068 - accuracy: 0.7050 - val_loss: 1.0884 - val_accuracy: 0.6808\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.0350 - accuracy: 0.6968 - val_loss: 1.1736 - val_accuracy: 0.6656\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.0360 - accuracy: 0.6930 - val_loss: 1.1529 - val_accuracy: 0.6582\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 13s 331ms/step - loss: 0.9947 - accuracy: 0.7042 - val_loss: 1.0257 - val_accuracy: 0.6980\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 15s 384ms/step - loss: 0.9354 - accuracy: 0.7194 - val_loss: 1.0286 - val_accuracy: 0.6936\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.8935 - accuracy: 0.7321 - val_loss: 0.9811 - val_accuracy: 0.7101\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.9412 - accuracy: 0.7188 - val_loss: 1.0306 - val_accuracy: 0.6994\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.9096 - accuracy: 0.7318 - val_loss: 1.0337 - val_accuracy: 0.6935\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.8677 - accuracy: 0.7418 - val_loss: 0.9805 - val_accuracy: 0.7037\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.8653 - accuracy: 0.7400 - val_loss: 1.0909 - val_accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 16s 407ms/step - loss: 0.8656 - accuracy: 0.7401 - val_loss: 0.9538 - val_accuracy: 0.7257\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 10s 256ms/step - loss: 0.8147 - accuracy: 0.7559 - val_loss: 0.9443 - val_accuracy: 0.7251\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 0.9025 - accuracy: 0.7288 - val_loss: 1.0278 - val_accuracy: 0.6995\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.8210 - accuracy: 0.7544 - val_loss: 0.9404 - val_accuracy: 0.7228\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.7770 - accuracy: 0.7661 - val_loss: 0.9585 - val_accuracy: 0.7214\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.7503 - accuracy: 0.7714 - val_loss: 0.9596 - val_accuracy: 0.7226\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 13s 332ms/step - loss: 0.8016 - accuracy: 0.7569 - val_loss: 1.1077 - val_accuracy: 0.6670\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 14s 357ms/step - loss: 0.8158 - accuracy: 0.7568 - val_loss: 0.9191 - val_accuracy: 0.7308\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 14s 364ms/step - loss: 0.7381 - accuracy: 0.7750 - val_loss: 0.9312 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 14s 364ms/step - loss: 0.7041 - accuracy: 0.7856 - val_loss: 0.9759 - val_accuracy: 0.7371\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 15s 374ms/step - loss: 0.7090 - accuracy: 0.7821 - val_loss: 0.9901 - val_accuracy: 0.7285\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 16s 410ms/step - loss: 0.6929 - accuracy: 0.7867 - val_loss: 1.0283 - val_accuracy: 0.7186\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 0.6853 - accuracy: 0.7916 - val_loss: 1.0109 - val_accuracy: 0.7381\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 0.6870 - accuracy: 0.7921 - val_loss: 1.0315 - val_accuracy: 0.7236\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 0.7155 - accuracy: 0.7836 - val_loss: 0.9158 - val_accuracy: 0.7447\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.6875 - accuracy: 0.7920 - val_loss: 0.8887 - val_accuracy: 0.7512\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.6506 - accuracy: 0.8025 - val_loss: 0.9047 - val_accuracy: 0.7428\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 0.6781 - accuracy: 0.7937 - val_loss: 0.9013 - val_accuracy: 0.7427\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 15s 371ms/step - loss: 0.6512 - accuracy: 0.8020 - val_loss: 0.9329 - val_accuracy: 0.7518\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 15s 372ms/step - loss: 0.6318 - accuracy: 0.8062 - val_loss: 0.8911 - val_accuracy: 0.7526\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.6856 - accuracy: 0.7906 - val_loss: 0.9685 - val_accuracy: 0.7377\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.7046 - accuracy: 0.7874 - val_loss: 0.9327 - val_accuracy: 0.7348\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 16s 392ms/step - loss: 0.6934 - accuracy: 0.7917 - val_loss: 0.9324 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 0.6497 - accuracy: 0.8020 - val_loss: 0.9350 - val_accuracy: 0.7482\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 16s 412ms/step - loss: 0.6424 - accuracy: 0.8044 - val_loss: 0.9187 - val_accuracy: 0.7599\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 16s 406ms/step - loss: 0.6099 - accuracy: 0.8140 - val_loss: 0.8607 - val_accuracy: 0.7709\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 12s 295ms/step - loss: 0.5707 - accuracy: 0.8255 - val_loss: 0.8375 - val_accuracy: 0.7726\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.5603 - accuracy: 0.8276 - val_loss: 0.8632 - val_accuracy: 0.7737\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 0.5936 - accuracy: 0.8176 - val_loss: 0.8874 - val_accuracy: 0.7584\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.5688 - accuracy: 0.8257 - val_loss: 0.9661 - val_accuracy: 0.7513\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.5455 - accuracy: 0.8318 - val_loss: 0.9132 - val_accuracy: 0.7646\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.5128 - accuracy: 0.8406 - val_loss: 0.8976 - val_accuracy: 0.7606\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 9s 235ms/step - loss: 0.4986 - accuracy: 0.8446 - val_loss: 0.8797 - val_accuracy: 0.7727\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 0.4853 - accuracy: 0.8490 - val_loss: 0.8936 - val_accuracy: 0.7735\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 0.4685 - accuracy: 0.8529 - val_loss: 0.8791 - val_accuracy: 0.7796\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.4624 - accuracy: 0.8554 - val_loss: 0.8943 - val_accuracy: 0.7750\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.4537 - accuracy: 0.8579Restoring model weights from the end of the best epoch: 63.\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.4537 - accuracy: 0.8579 - val_loss: 0.9374 - val_accuracy: 0.7736\n",
      "Epoch 73: early stopping\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.8375 - accuracy: 0.7726\n",
      ">0.773\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 11s 250ms/step - loss: 20.5678 - accuracy: 0.2016 - val_loss: 2.9529 - val_accuracy: 0.2724\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 2.5026 - accuracy: 0.3718 - val_loss: 2.3165 - val_accuracy: 0.3699\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 2.1284 - accuracy: 0.4637 - val_loss: 2.1078 - val_accuracy: 0.4407\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.9436 - accuracy: 0.5132 - val_loss: 2.1560 - val_accuracy: 0.4154\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.8833 - accuracy: 0.5192 - val_loss: 1.8966 - val_accuracy: 0.4724\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.7708 - accuracy: 0.5342 - val_loss: 1.8031 - val_accuracy: 0.5059\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.7038 - accuracy: 0.5443 - val_loss: 1.8026 - val_accuracy: 0.5001\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.6578 - accuracy: 0.5500 - val_loss: 1.7176 - val_accuracy: 0.5216\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 10s 254ms/step - loss: 1.6186 - accuracy: 0.5570 - val_loss: 1.7527 - val_accuracy: 0.5099\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 16s 401ms/step - loss: 1.6014 - accuracy: 0.5620 - val_loss: 1.5892 - val_accuracy: 0.5472\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 1.5387 - accuracy: 0.5733 - val_loss: 1.5799 - val_accuracy: 0.5589\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 1.5102 - accuracy: 0.5843 - val_loss: 1.5492 - val_accuracy: 0.5501\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 1.4731 - accuracy: 0.5924 - val_loss: 1.4985 - val_accuracy: 0.5776\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 1.4291 - accuracy: 0.6046 - val_loss: 1.5335 - val_accuracy: 0.5632\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 1.3911 - accuracy: 0.6154 - val_loss: 1.4732 - val_accuracy: 0.5805\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 1.3523 - accuracy: 0.6237 - val_loss: 1.4972 - val_accuracy: 0.5760\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 15s 380ms/step - loss: 1.3712 - accuracy: 0.6191 - val_loss: 1.4290 - val_accuracy: 0.5876\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 10s 244ms/step - loss: 1.3926 - accuracy: 0.6103 - val_loss: 1.4458 - val_accuracy: 0.5909\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4252 - accuracy: 0.5989 - val_loss: 1.4789 - val_accuracy: 0.5735\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4001 - accuracy: 0.6081 - val_loss: 1.4175 - val_accuracy: 0.5859\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.3789 - accuracy: 0.6099 - val_loss: 1.3512 - val_accuracy: 0.6048\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.3332 - accuracy: 0.6214 - val_loss: 1.2922 - val_accuracy: 0.6333\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.3067 - accuracy: 0.6313 - val_loss: 1.3202 - val_accuracy: 0.6354\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.2994 - accuracy: 0.6313 - val_loss: 1.4228 - val_accuracy: 0.5961\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.2944 - accuracy: 0.6342 - val_loss: 1.2612 - val_accuracy: 0.6404\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.2168 - accuracy: 0.6534 - val_loss: 1.2009 - val_accuracy: 0.6528\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1882 - accuracy: 0.6599 - val_loss: 1.2023 - val_accuracy: 0.6519\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2187 - accuracy: 0.6506 - val_loss: 1.2273 - val_accuracy: 0.6451\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.1984 - accuracy: 0.6544 - val_loss: 1.1703 - val_accuracy: 0.6593\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.1719 - accuracy: 0.6619 - val_loss: 1.2054 - val_accuracy: 0.6523\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 1.2221 - accuracy: 0.6484 - val_loss: 1.2619 - val_accuracy: 0.6404\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1330 - accuracy: 0.6715 - val_loss: 1.1031 - val_accuracy: 0.6809\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 1.1036 - accuracy: 0.6770 - val_loss: 1.1667 - val_accuracy: 0.6529\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.1257 - accuracy: 0.6716 - val_loss: 1.1316 - val_accuracy: 0.6724\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.0731 - accuracy: 0.6870 - val_loss: 1.0965 - val_accuracy: 0.6840\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.0436 - accuracy: 0.6976 - val_loss: 1.0613 - val_accuracy: 0.7001\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 13s 336ms/step - loss: 1.0036 - accuracy: 0.7094 - val_loss: 1.0186 - val_accuracy: 0.7127\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.9675 - accuracy: 0.7201 - val_loss: 1.0316 - val_accuracy: 0.7115\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 16s 396ms/step - loss: 0.9947 - accuracy: 0.7110 - val_loss: 1.0361 - val_accuracy: 0.7058\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.9585 - accuracy: 0.7213 - val_loss: 1.0180 - val_accuracy: 0.7088\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.9421 - accuracy: 0.7256 - val_loss: 1.0115 - val_accuracy: 0.7164\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 15s 386ms/step - loss: 0.9644 - accuracy: 0.7236 - val_loss: 1.1477 - val_accuracy: 0.6826\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 16s 397ms/step - loss: 1.1080 - accuracy: 0.6849 - val_loss: 1.0291 - val_accuracy: 0.6996\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 11s 278ms/step - loss: 0.9256 - accuracy: 0.7312 - val_loss: 0.9779 - val_accuracy: 0.7218\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 0.9027 - accuracy: 0.7360 - val_loss: 1.0391 - val_accuracy: 0.7052\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.9124 - accuracy: 0.7347 - val_loss: 1.0038 - val_accuracy: 0.7228\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.8689 - accuracy: 0.7439 - val_loss: 0.9222 - val_accuracy: 0.7426\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 12s 310ms/step - loss: 0.8365 - accuracy: 0.7533 - val_loss: 0.9091 - val_accuracy: 0.7422\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 16s 394ms/step - loss: 0.9229 - accuracy: 0.7322 - val_loss: 1.1137 - val_accuracy: 0.6791\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.9774 - accuracy: 0.7154 - val_loss: 1.0130 - val_accuracy: 0.7006\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 16s 395ms/step - loss: 0.8721 - accuracy: 0.7445 - val_loss: 0.8994 - val_accuracy: 0.7494\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 16s 398ms/step - loss: 0.8017 - accuracy: 0.7616 - val_loss: 0.9022 - val_accuracy: 0.7467\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 16s 400ms/step - loss: 0.7771 - accuracy: 0.7666 - val_loss: 0.8922 - val_accuracy: 0.7464\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.7693 - accuracy: 0.7687 - val_loss: 0.8993 - val_accuracy: 0.7471\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 12s 287ms/step - loss: 0.7629 - accuracy: 0.7700 - val_loss: 0.9257 - val_accuracy: 0.7361\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 9s 238ms/step - loss: 0.7736 - accuracy: 0.7672 - val_loss: 0.9277 - val_accuracy: 0.7409\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 0.7946 - accuracy: 0.7627 - val_loss: 0.9040 - val_accuracy: 0.7436\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.8031 - accuracy: 0.7622 - val_loss: 0.8770 - val_accuracy: 0.7505\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 10s 254ms/step - loss: 0.7397 - accuracy: 0.7769 - val_loss: 0.8749 - val_accuracy: 0.7567\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.6969 - accuracy: 0.7868 - val_loss: 0.8597 - val_accuracy: 0.7680\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 0.7423 - accuracy: 0.7771 - val_loss: 1.3984 - val_accuracy: 0.6031\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 1.1278 - accuracy: 0.6816 - val_loss: 1.1921 - val_accuracy: 0.6545\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.9819 - accuracy: 0.7136 - val_loss: 0.9749 - val_accuracy: 0.7121\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 0.7964 - accuracy: 0.7591 - val_loss: 0.9316 - val_accuracy: 0.7402\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 0.7421 - accuracy: 0.7752 - val_loss: 0.8985 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.7030 - accuracy: 0.7866 - val_loss: 0.9654 - val_accuracy: 0.7461\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 9s 233ms/step - loss: 0.7240 - accuracy: 0.7807 - val_loss: 0.9054 - val_accuracy: 0.7604\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.6826 - accuracy: 0.7917 - val_loss: 1.0043 - val_accuracy: 0.7505\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 0.6940 - accuracy: 0.7886 - val_loss: 0.8974 - val_accuracy: 0.7651\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.6648 - accuracy: 0.7956Restoring model weights from the end of the best epoch: 60.\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 0.6648 - accuracy: 0.7956 - val_loss: 0.9546 - val_accuracy: 0.7626\n",
      "Epoch 70: early stopping\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.8597 - accuracy: 0.7680\n",
      ">0.768\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 21s 434ms/step - loss: 16.4706 - accuracy: 0.2570 - val_loss: 2.4688 - val_accuracy: 0.3861\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 2.3565 - accuracy: 0.3854 - val_loss: 2.1892 - val_accuracy: 0.4077\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 2.1760 - accuracy: 0.4121 - val_loss: 2.0187 - val_accuracy: 0.4717\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 2.0659 - accuracy: 0.4505 - val_loss: 1.9291 - val_accuracy: 0.5065\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 1.9736 - accuracy: 0.4830 - val_loss: 1.8484 - val_accuracy: 0.5343\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 16s 404ms/step - loss: 1.9095 - accuracy: 0.5018 - val_loss: 1.8038 - val_accuracy: 0.5541\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 1.8662 - accuracy: 0.5101 - val_loss: 1.7988 - val_accuracy: 0.5544\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 1.8471 - accuracy: 0.5106 - val_loss: 1.7309 - val_accuracy: 0.5750\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.7991 - accuracy: 0.5230 - val_loss: 1.6670 - val_accuracy: 0.5843\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.7425 - accuracy: 0.5335 - val_loss: 1.6560 - val_accuracy: 0.5840\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.7190 - accuracy: 0.5401 - val_loss: 1.5640 - val_accuracy: 0.6005\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.6611 - accuracy: 0.5503 - val_loss: 1.5254 - val_accuracy: 0.6009\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.6396 - accuracy: 0.5537 - val_loss: 1.4936 - val_accuracy: 0.6058\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.6234 - accuracy: 0.5568 - val_loss: 1.5526 - val_accuracy: 0.5983\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.6278 - accuracy: 0.5531 - val_loss: 1.4872 - val_accuracy: 0.6082\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.6137 - accuracy: 0.5560 - val_loss: 1.4583 - val_accuracy: 0.6118\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 10s 243ms/step - loss: 1.6011 - accuracy: 0.5617 - val_loss: 1.4128 - val_accuracy: 0.6249\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.5350 - accuracy: 0.5749 - val_loss: 1.3842 - val_accuracy: 0.6200\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4980 - accuracy: 0.5863 - val_loss: 1.3803 - val_accuracy: 0.6261\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.4818 - accuracy: 0.5884 - val_loss: 1.3651 - val_accuracy: 0.6305\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.4702 - accuracy: 0.5919 - val_loss: 1.3437 - val_accuracy: 0.6296\n",
      "Epoch 22/200\n",
      "40/40 [==============================] - 10s 240ms/step - loss: 1.4331 - accuracy: 0.6001 - val_loss: 1.3329 - val_accuracy: 0.6436\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.4472 - accuracy: 0.6000 - val_loss: 1.3126 - val_accuracy: 0.6453\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4029 - accuracy: 0.6099 - val_loss: 1.2769 - val_accuracy: 0.6489\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.4018 - accuracy: 0.6059 - val_loss: 1.2883 - val_accuracy: 0.6347\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.3680 - accuracy: 0.6158 - val_loss: 1.4033 - val_accuracy: 0.6244\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 10s 238ms/step - loss: 1.3491 - accuracy: 0.6224 - val_loss: 1.2593 - val_accuracy: 0.6582\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 15s 375ms/step - loss: 1.3322 - accuracy: 0.6280 - val_loss: 1.2842 - val_accuracy: 0.6543\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 16s 403ms/step - loss: 1.3089 - accuracy: 0.6315 - val_loss: 1.2041 - val_accuracy: 0.6683\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 16s 409ms/step - loss: 1.2813 - accuracy: 0.6330 - val_loss: 1.1875 - val_accuracy: 0.6717\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 16s 405ms/step - loss: 1.2620 - accuracy: 0.6380 - val_loss: 1.1495 - val_accuracy: 0.6820\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 16s 408ms/step - loss: 1.2511 - accuracy: 0.6398 - val_loss: 1.1361 - val_accuracy: 0.6819\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 16s 402ms/step - loss: 1.2510 - accuracy: 0.6416 - val_loss: 1.1592 - val_accuracy: 0.6750\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 11s 262ms/step - loss: 1.2795 - accuracy: 0.6398 - val_loss: 1.2832 - val_accuracy: 0.6466\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2404 - accuracy: 0.6513 - val_loss: 1.1167 - val_accuracy: 0.6866\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.2026 - accuracy: 0.6497 - val_loss: 1.0705 - val_accuracy: 0.6971\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2065 - accuracy: 0.6543 - val_loss: 1.0895 - val_accuracy: 0.6817\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1947 - accuracy: 0.6531 - val_loss: 1.2511 - val_accuracy: 0.6490\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.2218 - accuracy: 0.6505 - val_loss: 1.0712 - val_accuracy: 0.6906\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 9s 237ms/step - loss: 1.1520 - accuracy: 0.6637 - val_loss: 1.0745 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1693 - accuracy: 0.6600 - val_loss: 1.1831 - val_accuracy: 0.6668\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 10s 241ms/step - loss: 1.2233 - accuracy: 0.6457 - val_loss: 1.1050 - val_accuracy: 0.6800\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1756 - accuracy: 0.6618 - val_loss: 1.0880 - val_accuracy: 0.6858\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 9s 236ms/step - loss: 1.1292 - accuracy: 0.6696 - val_loss: 1.1361 - val_accuracy: 0.6754\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 10s 242ms/step - loss: 1.1502 - accuracy: 0.6639 - val_loss: 1.1037 - val_accuracy: 0.6875\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.1277 - accuracy: 0.6706Restoring model weights from the end of the best epoch: 36.\n",
      "40/40 [==============================] - 10s 239ms/step - loss: 1.1277 - accuracy: 0.6706 - val_loss: 1.1072 - val_accuracy: 0.6826\n",
      "Epoch 46: early stopping\n",
      "10/10 [==============================] - 1s 71ms/step - loss: 1.0705 - accuracy: 0.6971\n",
      ">0.697\n",
      "\n",
      "Cross Validation with {num_folds} fold\n",
      "---------------------------------\n",
      "Estimated Accuracy 0.7002 (0.069812)\n"
     ]
    }
   ],
   "source": [
    "mean, std = cross_validation(5)\n",
    "print('\\nCross Validation with {num_folds} fold')\n",
    "print('---------------------------------')\n",
    "print('Estimated Accuracy %.4f (%.6f)' % (mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66b84508366a1ca0c082d2e8344b641f817a7c01e51353953628ecb8764b19b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
