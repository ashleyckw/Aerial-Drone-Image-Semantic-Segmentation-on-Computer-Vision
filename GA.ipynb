{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75704fb",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6966ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the genetic algorithm\n",
    "POPULATION_SIZE = 10\n",
    "MAX_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the range of values for the hyperparameters of the decision tree\n",
    "N_ESTIMATORS_RANGE = [50,100]\n",
    "MAX_DEPTH_RANGE = [2,6,10]\n",
    "MIN_SAMPLES_SPLIT_RANGE = [10,20]\n",
    "MIN_SAMPLES_LEAF_RANGE = [5,10]\n",
    "MAX_FEATURES_RANGE = Categorical(['auto', 'sqrt', 'log2'])\n",
    "BOOTSTRAP_RANGE = [True, False]\n",
    "\n",
    "# Create the initial population of random forest\n",
    "def create_population():\n",
    "    population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        n_estimators = random.choice(N_ESTIMATORS_RANGE)\n",
    "        max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "        min_samples_split = random.choice(MIN_SAMPLES_SPLIT_RANGE)\n",
    "        min_samples_leaf = random.choice(MIN_SAMPLES_LEAF_RANGE)\n",
    "        max_features = random.choice(MAX_FEATURES_RANGE)\n",
    "        bootstrap = random.choice(BOOTSTRAP_RANGE)\n",
    "        \n",
    "        rfc = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                      max_depth=max_depth, \n",
    "                                      min_samples_split=min_samples_split, \n",
    "                                      min_samples_leaf=min_samples_leaf,\n",
    "                                      max_features=max_features,\n",
    "                                      bootstrap=bootstrap)\n",
    "        population.append(rfc)\n",
    "    return population\n",
    "\n",
    "# Evaluate the fitness of each random forest in the population\n",
    "def evaluate_fitness(population, X_train, y_train, X_test, y_test):\n",
    "    fitness_scores = []\n",
    "    for tree in population:\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        fitness_scores.append(accuracy_score(y_test, y_pred))\n",
    "    return fitness_scores\n",
    "\n",
    "# Select the parents for the next generation using tournament selection\n",
    "def select_parents(fitness_scores):\n",
    "    parent1 = population[random.choice(range(len(population)))]\n",
    "    parent2 = population[random.choice(range(len(population)))]\n",
    "    if fitness_scores[parent1] > fitness_scores[parent2]:\n",
    "        return parent1\n",
    "    else:\n",
    "        return parent2\n",
    "\n",
    "# Crossover two parents to create a new child\n",
    "def crossover(parent1, parent2):\n",
    "    child = RandomForestClassifier(n_estimators=10)\n",
    "    child.n_estimators = parent1.n_estimators if random.random() < 0.5 else parent2.n_estimators\n",
    "    child.max_depth = parent1.max_depth if random.random() < 0.5 else parent2.max_depth\n",
    "    child.min_samples_split = parent1.min_samples_split if random.random() < 0.5 else parent2.min_samples_split\n",
    "    child.min_samples_leaf = parent1.min_samples_leaf if random.random() < 0.5 else parent2.min_samples_leaf\n",
    "    child.max_features = parent1.max_features if random.random() < 0.5 else parent2.max_features\n",
    "    child.bootstrap = parent1.bootstrap if random.random() < 0.5 else parent2.bootstrap\n",
    "    return child\n",
    "\n",
    "# Mutate the random forest by randomly changing one hyperparameter\n",
    "def mutate(tree):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        tree.n_estimators = random.choice(N_ESTIMATORS_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.min_samples_split = random.choice(MIN_SAMPLES_SPLIT_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.min_samples_leaf = random.choice(MIN_SAMPLES_LEAF_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.max_features = random.choice(MAX_FEATURES_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.bootstrap = random.choice(BOOTSTRAP_RANGE)\n",
    "\n",
    "# Run the genetic algorithm to optimize the random forest\n",
    "population = create_population()\n",
    "\n",
    "for generation in range(MAX_GENERATIONS):\n",
    "    fitness_scores = evaluate_fitness(population, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    new_population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        parent1 = select_parents(fitness_scores)\n",
    "        parent2 = select_parents(fitness_scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e3602",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe202368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the genetic algorithm\n",
    "POPULATION_SIZE = 10\n",
    "MAX_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the range of values for the hyperparameters of the decision tree\n",
    "MAX_DEPTH_RANGE = [2,6,10]\n",
    "MIN_SAMPLES_SPLIT_RANGE = [10,20]\n",
    "MIN_SAMPLES_LEAF_RANGE = [5,10]\n",
    "MAX_FEATURES_RANGE = Categorical(['auto', 'sqrt', 'log2'])\n",
    "\n",
    "# Create the initial population of decision trees\n",
    "def create_population():\n",
    "    population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "        min_samples_split = random.choice(MIN_SAMPLES_SPLIT_RANGE)\n",
    "        min_samples_leaf = random.choice(MIN_SAMPLES_LEAF_RANGE)\n",
    "        max_features = random.choice(MAX_FEATURES_RANGE)\n",
    "        \n",
    "        tree = DecisionTreeClassifier(max_depth=max_depth, \n",
    "                                      min_samples_split=min_samples_split, \n",
    "                                      min_samples_leaf=min_samples_leaf,\n",
    "                                      max_features=max_features)\n",
    "        population.append(tree)\n",
    "    return population\n",
    "\n",
    "# Evaluate the fitness of each decision tree in the population\n",
    "def evaluate_fitness(population, X_train, y_train, X_test, y_test):\n",
    "    fitness_scores = []\n",
    "    for tree in population:\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        fitness_scores.append(accuracy_score(y_test, y_pred))\n",
    "    return fitness_scores\n",
    "\n",
    "# Select the parents for the next generation using tournament selection\n",
    "def select_parents(fitness_scores):\n",
    "    parent1 = population[random.choice(range(len(population)))]\n",
    "    parent2 = population[random.choice(range(len(population)))]\n",
    "    if fitness_scores[parent1] > fitness_scores[parent2]:\n",
    "        return parent1\n",
    "    else:\n",
    "        return parent2\n",
    "\n",
    "# Crossover two parents to create a new child\n",
    "def crossover(parent1, parent2):\n",
    "    child = DecisionTreeClassifier()\n",
    "    child.max_depth = parent1.max_depth if random.random() < 0.5 else parent2.max_depth\n",
    "    child.min_samples_split = parent1.min_samples_split if random.random() < 0.5 else parent2.min_samples_split\n",
    "    child.min_samples_leaf = parent1.min_samples_leaf if random.random() < 0.5 else parent2.min_samples_leaf\n",
    "    child.max_features = parent1.max_features if random.random() < 0.5 else parent2.max_features\n",
    "    return child\n",
    "\n",
    "# Mutate the decision tree by randomly changing one hyperparameter\n",
    "def mutate(tree):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        tree.max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.min_samples_split = random.choice(MIN_SAMPLES_SPLIT_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.min_samples_leaf = random.choice(MIN_SAMPLES_LEAF_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.max_features = random.choice(MAX_FEATURES_RANGE)\n",
    "\n",
    "# Run the genetic algorithm to optimize the decision tree\n",
    "population = create_population()\n",
    "\n",
    "for generation in range(MAX_GENERATIONS):\n",
    "    fitness_scores = evaluate_fitness(population, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    new_population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        parent1 = select_parents(fitness_scores)\n",
    "        parent2 = select_parents(fitness_scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325e14c",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the genetic algorithm\n",
    "POPULATION_SIZE = 10\n",
    "MAX_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the range of values for the hyperparameters of the naive bayes\n",
    "VAR_SMOOTHING_RANGE = Real(1e-10, 1e-6, prior='log-uniform')\n",
    "\n",
    "# Create the initial population of naive bayes\n",
    "def create_population():\n",
    "    population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        var_smoothing = random.choice(VAR_SMOOTHING_RANGE)\n",
    "        \n",
    "        nb = GaussianNB(var_smoothing=var_smoothing)\n",
    "        population.append(nb)\n",
    "    return population\n",
    "\n",
    "# Evaluate the fitness of each naive bayes in the population\n",
    "def evaluate_fitness(population, X_train, y_train, X_test, y_test):\n",
    "    fitness_scores = []\n",
    "    for tree in population:\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        fitness_scores.append(accuracy_score(y_test, y_pred))\n",
    "    return fitness_scores\n",
    "\n",
    "# Select the parents for the next generation using tournament selection\n",
    "def select_parents(fitness_scores):\n",
    "    parent1 = population[random.choice(range(len(population)))]\n",
    "    parent2 = population[random.choice(range(len(population)))]\n",
    "    if fitness_scores[parent1] > fitness_scores[parent2]:\n",
    "        return parent1\n",
    "    else:\n",
    "        return parent2\n",
    "\n",
    "# Crossover two parents to create a new child\n",
    "def crossover(parent1, parent2):\n",
    "    child = GaussianNB()\n",
    "    child.var_smoothing = parent1.var_smoothing if random.random() < 0.5 else parent2.var_smoothing\n",
    "    return child\n",
    "\n",
    "# Mutate the naive bayes by randomly changing one hyperparameter\n",
    "def mutate(tree):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        tree.var_smoothing = random.choice(VAR_SMOOTHING_RANGE)\n",
    "\n",
    "# Run the genetic algorithm to optimize the naive bayes\n",
    "population = create_population()\n",
    "\n",
    "for generation in range(MAX_GENERATIONS):\n",
    "    fitness_scores = evaluate_fitness(population, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    new_population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        parent1 = select_parents(fitness_scores)\n",
    "        parent2 = select_parents(fitness_scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdf307",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900adb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the genetic algorithm\n",
    "POPULATION_SIZE = 10\n",
    "MAX_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the range of values for the hyperparameters of the KNN\n",
    "N_NEIGHBORS_RANGE = [2,5,10]\n",
    "WEIGHTS_RANGE = Categorical(['uniform', 'distance'])\n",
    "P_RANGE = Integer(1, 2)\n",
    "\n",
    "# Create the initial population of KNN\n",
    "def create_population():\n",
    "    population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        n_neighbors = random.choice(N_NEIGHBORS_RANGE)\n",
    "        weights = random.choice(WEIGHTS_RANGE)\n",
    "        p = random.choice(P_RANGE)\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors,weights=weights,p=p)\n",
    "        population.append(knn)\n",
    "    return population\n",
    "\n",
    "# Evaluate the fitness of each KNN in the population\n",
    "def evaluate_fitness(population, X_train, y_train, X_test, y_test):\n",
    "    fitness_scores = []\n",
    "    for tree in population:\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        fitness_scores.append(accuracy_score(y_test, y_pred))\n",
    "    return fitness_scores\n",
    "\n",
    "# Select the parents for the next generation using tournament selection\n",
    "def select_parents(fitness_scores):\n",
    "    parent1 = population[random.choice(range(len(population)))]\n",
    "    parent2 = population[random.choice(range(len(population)))]\n",
    "    if fitness_scores[parent1] > fitness_scores[parent2]:\n",
    "        return parent1\n",
    "    else:\n",
    "        return parent2\n",
    "\n",
    "# Crossover two parents to create a new child\n",
    "def crossover(parent1, parent2):\n",
    "    child = KNeighborsClassifier()\n",
    "    child.n_neighbors = parent1.n_neighbors if random.random() < 0.5 else parent2.n_neighbors\n",
    "    child.weights = parent1.weights if random.random() < 0.5 else parent2.weights\n",
    "    child.p = parent1.p if random.random() < 0.5 else parent2.p\n",
    "    return child\n",
    "\n",
    "# Mutate the KNN by randomly changing one hyperparameter\n",
    "def mutate(tree):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        tree.n_neighbors = random.choice(N_NEIGHBORS_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.weights = random.choice(WEIGHTS_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.p = random.choice(P_RANGE)\n",
    "\n",
    "# Run the genetic algorithm to optimize the KNN\n",
    "population = create_population()\n",
    "\n",
    "for generation in range(MAX_GENERATIONS):\n",
    "    fitness_scores = evaluate_fitness(population, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    new_population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        parent1 = select_parents(fitness_scores)\n",
    "        parent2 = select_parents(fitness_scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40b2fc",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3529c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the genetic algorithm\n",
    "POPULATION_SIZE = 10\n",
    "MAX_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the range of values for the hyperparameters of the XGB\n",
    "N_ESTIMATORS_RANGE = [50,100]\n",
    "MAX_DEPTH_RANGE = [5,10]\n",
    "COLSAMPLE_BYTREE_RANGE = Real(0.1, 1.0, prior='uniform')\n",
    "MIN_CHILD_WEIGHT_RANGE = [5,10,20]\n",
    "GAMMA_RANGE = Real(0, 10, prior='uniform')\n",
    "\n",
    "# Create the initial population of XGB\n",
    "def create_population():\n",
    "    population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        n_estimators = random.choice(N_ESTIMATORS_RANGE)\n",
    "        max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "        colsample_bytree = random.choice(COLSAMPLE_BYTREE_RANGE)\n",
    "        min_child_weight = random.choice(MIN_CHILD_WEIGHT_RANGE)\n",
    "        gamma = random.choice(GAMMA_RANGE)\n",
    "        \n",
    "        xgbc = XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,\n",
    "                            colsample_bytree=colsample_bytree,\n",
    "                            min_child_weight=min_child_weight,\n",
    "                            gamma=gamma)\n",
    "        population.append(xgbc)\n",
    "    return population\n",
    "\n",
    "# Evaluate the fitness of each XGB in the population\n",
    "def evaluate_fitness(population, X_train, y_train, X_test, y_test):\n",
    "    fitness_scores = []\n",
    "    for tree in population:\n",
    "        tree.fit(X_train, y_train)\n",
    "        y_pred = tree.predict(X_test)\n",
    "        fitness_scores.append(accuracy_score(y_test, y_pred))\n",
    "    return fitness_scores\n",
    "\n",
    "# Select the parents for the next generation using tournament selection\n",
    "def select_parents(fitness_scores):\n",
    "    parent1 = population[random.choice(range(len(population)))]\n",
    "    parent2 = population[random.choice(range(len(population)))]\n",
    "    if fitness_scores[parent1] > fitness_scores[parent2]:\n",
    "        return parent1\n",
    "    else:\n",
    "        return parent2\n",
    "\n",
    "# Crossover two parents to create a new child\n",
    "def crossover(parent1, parent2):\n",
    "    xgbc = XGBClassifier(n_estimators=10)\n",
    "    child.n_estimators = parent1.n_estimators if random.random() < 0.5 else parent2.n_estimators\n",
    "    child.max_depth = parent1.max_depth if random.random() < 0.5 else parent2.max_depth\n",
    "    child.colsample_bytree = parent1.colsample_bytree if random.random() < 0.5 else parent2.colsample_bytree\n",
    "    child.min_child_weight = parent1.min_child_weight if random.random() < 0.5 else parent2.min_child_weight\n",
    "    child.gamma = parent1.gamma if random.random() < 0.5 else parent2.gamma\n",
    "    return child\n",
    "\n",
    "# Mutate the XGB by randomly changing one hyperparameter\n",
    "def mutate(tree):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        tree.n_estimators = random.choice(N_ESTIMATORS_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.max_depth = random.choice(MAX_DEPTH_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.colsample_bytree = random.choice(COLSAMPLE_BYTREE_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.min_child_weight = random.choice(MIN_CHILD_WEIGHT_RANGE)\n",
    "    elif random.random() < MUTATION_RATE:\n",
    "        tree.gamma = random.choice(GAMMA_RANGE)\n",
    "\n",
    "# Run the genetic algorithm to optimize the XGB\n",
    "population = create_population()\n",
    "\n",
    "for generation in range(MAX_GENERATIONS):\n",
    "    fitness_scores = evaluate_fitness(population, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    new_population = []\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        parent1 = select_parents(fitness_scores)\n",
    "        parent2 = select_parents(fitness_scores)\n",
    "        child = crossover(parent1, parent2)\n",
    "        mutate(child)\n",
    "        new_population.append(child)\n",
    "    \n",
    "    population = new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f905737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc8c06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
